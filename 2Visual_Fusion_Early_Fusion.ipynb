{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGlg7uxki1Cq"
      },
      "source": [
        "##0 - Load the Data and Visualize it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RYckDyji8H1"
      },
      "source": [
        "### Link Google Colab to Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrs7OD_Vi_Zs"
      },
      "source": [
        "### Import the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.10.0\n",
            "\n",
            "0.18.0\n",
            "\n",
            "3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]\n"
          ]
        }
      ],
      "source": [
        "print(cv.__version__)\n",
        "print()\n",
        "print(o3d.__version__)\n",
        "print()\n",
        "import sys\n",
        "print(sys.version)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BC_e1h8MICKX"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import open3d as o3d\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr79FMSMpT8E"
      },
      "source": [
        "### Load the Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qP3-j5OAKhT2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "000031.png\n",
            "000035.png\n",
            "000060.png\n",
            "000080.png\n",
            "000134.png\n",
            "[WindowsPath('data/img/000031.png'), WindowsPath('data/img/000035.png'), WindowsPath('data/img/000060.png'), WindowsPath('data/img/000080.png'), WindowsPath('data/img/000134.png')]\n",
            "\n",
            "000031.txt\n",
            "000035.txt\n",
            "000060.txt\n",
            "000080.txt\n",
            "000134.txt\n",
            "[WindowsPath('data/label/000031.txt'), WindowsPath('data/label/000035.txt'), WindowsPath('data/label/000060.txt'), WindowsPath('data/label/000080.txt'), WindowsPath('data/label/000134.txt')]\n",
            "\n",
            "000031.pcd\n",
            "000035.pcd\n",
            "000060.pcd\n",
            "000080.pcd\n",
            "000134.pcd\n",
            "[WindowsPath('data/velodyne/000031.pcd'), WindowsPath('data/velodyne/000035.pcd'), WindowsPath('data/velodyne/000060.pcd'), WindowsPath('data/velodyne/000080.pcd'), WindowsPath('data/velodyne/000134.pcd')]\n",
            "\n",
            "000031.txt\n",
            "000035.txt\n",
            "000060.txt\n",
            "000080.txt\n",
            "000134.txt\n",
            "[WindowsPath('data/calib/000031.txt'), WindowsPath('data/calib/000035.txt'), WindowsPath('data/calib/000060.txt'), WindowsPath('data/calib/000080.txt'), WindowsPath('data/calib/000134.txt')]\n",
            "\n",
            "(375, 1242, 3) (121291, 3)\n",
            "[[[133 159 244]\n",
            "  [127 175 255]\n",
            "  [176 192 255]\n",
            "  ...\n",
            "  [ 72  91  69]\n",
            "  [ 71  93  66]\n",
            "  [ 75  95  62]]\n",
            "\n",
            " [[140 187 238]\n",
            "  [132 205 254]\n",
            "  [207 224 255]\n",
            "  ...\n",
            "  [ 49  82  72]\n",
            "  [ 58  83  74]\n",
            "  [ 75  87  78]]\n",
            "\n",
            " [[179 223 236]\n",
            "  [169 223 251]\n",
            "  [210 239 255]\n",
            "  ...\n",
            "  [ 74  88  81]\n",
            "  [103 108  88]\n",
            "  [152 129  92]]\n",
            "\n",
            " [[180 247 255]\n",
            "  [167 251 255]\n",
            "  [206 254 255]\n",
            "  ...\n",
            "  [168 183 119]\n",
            "  [213 213 130]\n",
            "  [255 207 162]]\n",
            "\n",
            " [[224 252 251]\n",
            "  [255 255 255]\n",
            "  [212 255 255]\n",
            "  ...\n",
            "  [157 255 239]\n",
            "  [189 238 229]\n",
            "  [208 209 233]]]\n"
          ]
        }
      ],
      "source": [
        "#make the object having all files in it \n",
        "img_files=sorted(Path(\"data/img\").glob(\"*.png\"))\n",
        "label_files=sorted(Path(\"data/label\").glob(\"*.txt\"))\n",
        "point_files=sorted(Path(\"data/velodyne\").glob(\"*.pcd\"))\n",
        "calib_files=sorted(Path(\"data/calib\").glob(\"*.txt\"))\n",
        "\n",
        "for file in img_files:\n",
        "    print(file.name )\n",
        "print(img_files)\n",
        "print()\n",
        "for file in label_files:\n",
        "    print(file.name)\n",
        "print(label_files)\n",
        "print()\n",
        "for file in point_files:\n",
        "    print(file.name)\n",
        "print(point_files)\n",
        "print()\n",
        "for file in calib_files:\n",
        "    print(file.name)\n",
        "print(calib_files)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "(375, 1242, 3) (121291, 3) \n",
            "\n",
            "Image shape: (375, 1242, 3)\n",
            "Number of LiDAR points: (121291, 3)\n",
            "[[[133 159 244]\n",
            "  [127 175 255]\n",
            "  [176 192 255]\n",
            "  ...\n",
            "  [ 72  91  69]\n",
            "  [ 71  93  66]\n",
            "  [ 75  95  62]]] \n",
            "\n",
            " [[21.75099945  2.53399992  0.94999999]]\n"
          ]
        }
      ],
      "source": [
        "index=0\n",
        "img=cv.imread(str(img_files[index]))\n",
        "rgb_img=cv.cvtColor(img,cv.COLOR_BGR2RGB)\n",
        "cloud=o3d.io.read_point_cloud(str(point_files[index]))\n",
        "points=np.asarray(cloud.points)\n",
        "print()\n",
        "print(rgb_img.shape,points.shape,'\\n')\n",
        "print(\"Image shape:\", rgb_img.shape)  # (H, W, 3)\n",
        "print(\"Number of LiDAR points:\", points.shape)  # (N, 3)\n",
        "print(rgb_img[:1],\"\\n\\n\",points[:1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rbhQKptg-uK"
      },
      "source": [
        "### Optional - If your LiDAR file is in binary extension '.bin', use this piece of code to turn it into a '.pcd' and save it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00YaQZjrjRpW"
      },
      "source": [
        "### Visualize the Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnSsfviYjTxb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiNl7OdgjUri"
      },
      "source": [
        "### Visualize the Point Clouds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44-hPZXmTulS"
      },
      "source": [
        "## 1 - Project the Points in the Image <p>\n",
        "That part is possibly the hardest to understand and will require your full attention. We want to project the 3D points into the image.<p>\n",
        "\n",
        "It means we'll need to: <p>\n",
        "\n",
        "*   Select the Point that are **visible** in the image ðŸ¤”\n",
        "*   Convert the Points **from the LiDAR frame to the Camera Frame** ðŸ¤¯\n",
        "*   Find a way to project **from the Camera Frame to the Image Frame** ðŸ˜­\n",
        "\n",
        "<p>\n",
        "No worries here, we'll figure out everything together.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTqtmQJoBx-8"
      },
      "source": [
        "### 1.1 - Read the Calibration File\n",
        "\n",
        "The first step is to read the calibration files. For each image, we have an associated calibration file that states:<p>\n",
        "\n",
        "\n",
        "*   The instrinsic and extrinsic camera calibration parameters\n",
        "*   The velodyne to camera matrices\n",
        "*   All the other \"sensor A\" to \"sensor B\" matrices\n",
        "<p>\n",
        "They are made from this setup:<p>\n",
        "\n",
        "![link text](http://www.cvlibs.net/datasets/kitti/images/setup_top_view.png)\n",
        "\n",
        "Not everything matters to us here, only a few things:\n",
        "*    **Velo-To-Cam is a variable we'll call V2C** -- It gives the rotation and translation matrices from the Velodyne to the Left Grayscale camera.\n",
        "*    **R0_rect used in Stereo Vision to make the images co-planar.**\n",
        "*   **P2 is the matrix obtained after camera calibration**. It contains the intrinsic matrix K and the extrinsic.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSzz_3tf0xlX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZWuxKSFFEDA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ4qEcG9CNJq"
      },
      "source": [
        "### 1.2 - Project the Points in the Image\n",
        "\n",
        "The main formula we'll use will be as follows:<p>\n",
        "**Y(2D) = P x R0 x R|t x X (3D)** \n",
        "\n",
        "However, when looking at the dimensions:\n",
        "\n",
        "*   P: [3x4]\n",
        "*   R0: [3x3]\n",
        "*   R|t = Velo2Cam: [3x4]\n",
        "*   X: [3x1]\n",
        "\n",
        "We'll need to convert some points into Homogeneous Coordinates:\n",
        "* RO must go from 3x3 to 4x3\n",
        "* x must go from 3x1 to 4x1\n",
        "\n",
        "Then, to retrieve the cartesian system, we'll divide as explained in the course."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jB2aXeITxS8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PUKxLc5HFsd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxhDF3puLpXq"
      },
      "source": [
        "--- TODO ---\n",
        "Code the Project_velo_to_image function and test it for the first 5 points. Make sure it makes sense."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siG14wbNcVCK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0NSdCLpCgBP"
      },
      "source": [
        "### 1.4 - LiDAR in Image Field Of View"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cICtSHfD8I8Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVNFq-3gCnmL"
      },
      "source": [
        "###1.5 -- Get the LiDAR Points in Pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DOf4AXe8Kqf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaLfy002oOIG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmYX4Iex6JzH"
      },
      "source": [
        "## 2 - Detect Obstacles in 2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-Py5K64gDvQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJFi74VA7F0F"
      },
      "source": [
        "## 3 - Fuse Points Clouds & Bounding Boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q6V1HE265jk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0Qebe-FHViZ"
      },
      "source": [
        "**In this course, we'll see a few ways to filter outliers.** <p>\n",
        "Outliers are the points that belong to the bounding box, but not to the object.<p>\n",
        "Here's an example of outliers:<p>\n",
        "![outlier image](https://i.ibb.co/Fg0KV3k/Screenshot-2021-05-31-at-22-31-29.png)\n",
        "\n",
        "In this image, the points belong to the truck, but are also counted as part of the car.\n",
        "\n",
        "The first technique we can use for that is a shrink factor.\n",
        "Instead of considering the whole bounding box, we're considering only a part of it. **A common choice is 10-15% shrinking.**\n",
        "![image_shrinks](https://i.ibb.co/Zcgzz6F/Screenshot-2021-05-31-at-22-45-36.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pihcxsm7MWrk"
      },
      "source": [
        "--- TODO --- Code a function that return the points inside a bounding box according to a shrink factor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9VW-osNGbpe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DewS97_cLjxJ"
      },
      "source": [
        "**The second way will be through Outlier removal techniques. <p>**\n",
        "We can cite a few: 3 Sigma, RANSAC, and others..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOJamotbMxmR"
      },
      "source": [
        "--- TODO--- Code a function to remove the outliers according to One Sigma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bk6HfEgAsg9R"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTQBWN-vNQzL"
      },
      "source": [
        "-- TODO-- Code a function that implements the fusion between boxes and points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JF8wnxMuj_zQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6w7bFcYk03p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlrlH991R34T"
      },
      "source": [
        "### Build a Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWhXl-ftiIA6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhtJIYtTGLX1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAnmN-M6z5o_"
      },
      "source": [
        "## Comparing with the Ground Truth\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r07ai06Pz7TT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eZq-Put27fl"
      },
      "source": [
        "## Inferece the video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VieqzsWS2-Wk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMPtRj5EeuIl7Ba2PNclsyh",
      "collapsed_sections": [
        "XGlg7uxki1Cq",
        "1rbhQKptg-uK"
      ],
      "include_colab_link": true,
      "name": "Visual Fusion Early - Starter.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
